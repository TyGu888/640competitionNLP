{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0b92c1b",
   "metadata": {
    "papermill": {
     "duration": 0.007425,
     "end_time": "2022-10-31T21:30:32.647198",
     "exception": false,
     "start_time": "2022-10-31T21:30:32.639773",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# ðŸ¤—DeBERTa WeightedLayer + MeanPool KFold with TensorFlow\n",
    "\n",
    "Hi, everyone! This notebook is a DeBERTaV3 finetuning solution to [Feedback Prize - English Language Learning competition](https://www.kaggle.com/competitions/feedback-prize-english-language-learning). It covers:\n",
    "\n",
    "* MultilabelStratifiedKFold split of the data\n",
    "* HuggingFace DeBERTaV3 pre-trained model finetuning with Tensorflow\n",
    "* WeightedLayerPool + MeanPool TensorFlow implementation\n",
    "* An approximation of layer-wise learning rate decay\n",
    "* Ensemble of 5 folds inference\n",
    "* Submission\n",
    "\n",
    "In this compitition, I also have the following notebooks:\n",
    "\n",
    "* LB 0.44 - [RoBERTa finetuning](https://www.kaggle.com/code/electro/fp3-roberta-meanpool-kfold-tensorflow)\n",
    "* LB 0.46 - [BERT finetuning](https://www.kaggle.com/code/electro/fp3-bert-fine-tuning-tensorflow) | [BERT inference](https://www.kaggle.com/code/electro/fp3-bert-inference-tensorflow)\n",
    "* LB 0.53 - [basic EDA and bag-of-words solution](https://www.kaggle.com/code/electro/fp3-bag-of-words-tensorflow-starter). \n",
    "\n",
    "Please check them out if you are interested. \n",
    "\n",
    "If you like this notebook, please upvote it. Thank you."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62906eaf",
   "metadata": {
    "papermill": {
     "duration": 0.005987,
     "end_time": "2022-10-31T21:30:32.659675",
     "exception": false,
     "start_time": "2022-10-31T21:30:32.653688",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "100eaa0d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-31T21:30:32.674561Z",
     "iopub.status.busy": "2022-10-31T21:30:32.673717Z",
     "iopub.status.idle": "2022-10-31T21:30:39.951346Z",
     "shell.execute_reply": "2022-10-31T21:30:39.950269Z"
    },
    "papermill": {
     "duration": 7.288344,
     "end_time": "2022-10-31T21:30:39.954204",
     "exception": false,
     "start_time": "2022-10-31T21:30:32.665860",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF version: 2.6.4\n",
      "transformers version: 4.20.1\n"
     ]
    }
   ],
   "source": [
    "import os, gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "print(f'TF version: {tf.__version__}')\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import transformers\n",
    "print(f'transformers version: {transformers.__version__}')\n",
    "from transformers import logging as hf_logging\n",
    "hf_logging.set_verbosity_error()\n",
    "\n",
    "import sys\n",
    "sys.path.append('../input/iterativestratification')\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a10beb88",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-31T21:30:39.970722Z",
     "iopub.status.busy": "2022-10-31T21:30:39.968949Z",
     "iopub.status.idle": "2022-10-31T21:30:39.975686Z",
     "shell.execute_reply": "2022-10-31T21:30:39.974834Z"
    },
    "papermill": {
     "duration": 0.016253,
     "end_time": "2022-10-31T21:30:39.977697",
     "exception": false,
     "start_time": "2022-10-31T21:30:39.961444",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_seed(seed=42):\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "#     os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb153c2b",
   "metadata": {
    "papermill": {
     "duration": 0.006038,
     "end_time": "2022-10-31T21:30:39.990043",
     "exception": false,
     "start_time": "2022-10-31T21:30:39.984005",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1c66297",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-31T21:30:40.005278Z",
     "iopub.status.busy": "2022-10-31T21:30:40.003667Z",
     "iopub.status.idle": "2022-10-31T21:30:40.238783Z",
     "shell.execute_reply": "2022-10-31T21:30:40.237049Z"
    },
    "papermill": {
     "duration": 0.24458,
     "end_time": "2022-10-31T21:30:40.240905",
     "exception": false,
     "start_time": "2022-10-31T21:30:39.996325",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>cohesion</th>\n",
       "      <th>syntax</th>\n",
       "      <th>vocabulary</th>\n",
       "      <th>phraseology</th>\n",
       "      <th>grammar</th>\n",
       "      <th>conventions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0016926B079C</td>\n",
       "      <td>I think that students would benefit from learn...</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0022683E9EA5</td>\n",
       "      <td>When a problem is a change you have to let it ...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00299B378633</td>\n",
       "      <td>Dear, Principal\\n\\nIf u change the school poli...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>003885A45F42</td>\n",
       "      <td>The best time in life is when you become yours...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0049B1DF5CCC</td>\n",
       "      <td>Small act of kindness can impact in other peop...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        text_id                                          full_text  cohesion  \\\n",
       "0  0016926B079C  I think that students would benefit from learn...       3.5   \n",
       "1  0022683E9EA5  When a problem is a change you have to let it ...       2.5   \n",
       "2  00299B378633  Dear, Principal\\n\\nIf u change the school poli...       3.0   \n",
       "3  003885A45F42  The best time in life is when you become yours...       4.5   \n",
       "4  0049B1DF5CCC  Small act of kindness can impact in other peop...       2.5   \n",
       "\n",
       "   syntax  vocabulary  phraseology  grammar  conventions  \n",
       "0     3.5         3.0          3.0      4.0          3.0  \n",
       "1     2.5         3.0          2.0      2.0          2.5  \n",
       "2     3.5         3.0          3.0      3.0          2.5  \n",
       "3     4.5         4.5          4.5      4.0          5.0  \n",
       "4     3.0         3.0          3.0      2.5          2.5  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------DataFrame Summary---------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3911 entries, 0 to 3910\n",
      "Data columns (total 8 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   text_id      3911 non-null   object \n",
      " 1   full_text    3911 non-null   object \n",
      " 2   cohesion     3911 non-null   float64\n",
      " 3   syntax       3911 non-null   float64\n",
      " 4   vocabulary   3911 non-null   float64\n",
      " 5   phraseology  3911 non-null   float64\n",
      " 6   grammar      3911 non-null   float64\n",
      " 7   conventions  3911 non-null   float64\n",
      "dtypes: float64(6), object(2)\n",
      "memory usage: 244.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../input/feedback-prize-english-language-learning/train.csv')\n",
    "display(df.head())\n",
    "print('\\n---------DataFrame Summary---------')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c1bd73",
   "metadata": {
    "papermill": {
     "duration": 0.006506,
     "end_time": "2022-10-31T21:30:40.254425",
     "exception": false,
     "start_time": "2022-10-31T21:30:40.247919",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# CV Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0aa8cb35",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-31T21:30:40.269850Z",
     "iopub.status.busy": "2022-10-31T21:30:40.269223Z",
     "iopub.status.idle": "2022-10-31T21:30:40.395879Z",
     "shell.execute_reply": "2022-10-31T21:30:40.394867Z"
    },
    "papermill": {
     "duration": 0.136194,
     "end_time": "2022-10-31T21:30:40.397905",
     "exception": false,
     "start_time": "2022-10-31T21:30:40.261711",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    783\n",
       "0    782\n",
       "4    782\n",
       "3    782\n",
       "2    782\n",
       "Name: fold, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_FOLD = 5\n",
    "TARGET_COLS = ['cohesion', 'syntax', 'vocabulary', 'phraseology', 'grammar', 'conventions']\n",
    "\n",
    "skf = MultilabelStratifiedKFold(n_splits=N_FOLD, shuffle=True, random_state=42)\n",
    "for n, (train_index, val_index) in enumerate(skf.split(df, df[TARGET_COLS])):\n",
    "    df.loc[val_index, 'fold'] = int(n)\n",
    "df['fold'] = df['fold'].astype(int)\n",
    "df['fold'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "194dca11",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-31T21:30:40.414502Z",
     "iopub.status.busy": "2022-10-31T21:30:40.412948Z",
     "iopub.status.idle": "2022-10-31T21:30:40.553655Z",
     "shell.execute_reply": "2022-10-31T21:30:40.552653Z"
    },
    "papermill": {
     "duration": 0.151284,
     "end_time": "2022-10-31T21:30:40.556175",
     "exception": false,
     "start_time": "2022-10-31T21:30:40.404891",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.to_csv('./df_folds.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9621fae0",
   "metadata": {
    "papermill": {
     "duration": 0.006606,
     "end_time": "2022-10-31T21:30:40.569744",
     "exception": false,
     "start_time": "2022-10-31T21:30:40.563138",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3e7676e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-31T21:30:40.584582Z",
     "iopub.status.busy": "2022-10-31T21:30:40.584237Z",
     "iopub.status.idle": "2022-10-31T21:30:40.589062Z",
     "shell.execute_reply": "2022-10-31T21:30:40.588011Z"
    },
    "papermill": {
     "duration": 0.014711,
     "end_time": "2022-10-31T21:30:40.591289",
     "exception": false,
     "start_time": "2022-10-31T21:30:40.576578",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "MAX_LENGTH = 512\n",
    "BATCH_SIZE = 4\n",
    "DEBERTA_MODEL = \"../input/debertav3base\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1325ba87",
   "metadata": {
    "papermill": {
     "duration": 0.006489,
     "end_time": "2022-10-31T21:30:40.604485",
     "exception": false,
     "start_time": "2022-10-31T21:30:40.597996",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Why we should disable dropout in regression task, check this [discussion](https://www.kaggle.com/competitions/commonlitreadabilityprize/discussion/260729)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f863ff89",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-31T21:30:40.619343Z",
     "iopub.status.busy": "2022-10-31T21:30:40.618492Z",
     "iopub.status.idle": "2022-10-31T21:30:42.177980Z",
     "shell.execute_reply": "2022-10-31T21:30:42.176984Z"
    },
    "papermill": {
     "duration": 1.569364,
     "end_time": "2022-10-31T21:30:42.180382",
     "exception": false,
     "start_time": "2022-10-31T21:30:40.611018",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/transformers/convert_slow_tokenizer.py:435: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  \"The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option\"\n"
     ]
    }
   ],
   "source": [
    "tokenizer = transformers.AutoTokenizer.from_pretrained(DEBERTA_MODEL)\n",
    "tokenizer.save_pretrained('./tokenizer/')\n",
    "\n",
    "cfg = transformers.AutoConfig.from_pretrained(DEBERTA_MODEL, output_hidden_states=True)\n",
    "cfg.hidden_dropout_prob = 0\n",
    "cfg.attention_probs_dropout_prob = 0\n",
    "cfg.save_pretrained('./tokenizer/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a47078",
   "metadata": {
    "papermill": {
     "duration": 0.010896,
     "end_time": "2022-10-31T21:30:42.205235",
     "exception": false,
     "start_time": "2022-10-31T21:30:42.194339",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data Process Function\n",
    "\n",
    "To make use of HugggingFace DeBERTa model, we have to tokenize our input texts as the pretrained DeBERTa model requires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "edd770ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-31T21:30:42.219979Z",
     "iopub.status.busy": "2022-10-31T21:30:42.219674Z",
     "iopub.status.idle": "2022-10-31T21:30:42.225854Z",
     "shell.execute_reply": "2022-10-31T21:30:42.224857Z"
    },
    "papermill": {
     "duration": 0.016241,
     "end_time": "2022-10-31T21:30:42.228203",
     "exception": false,
     "start_time": "2022-10-31T21:30:42.211962",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def deberta_encode(texts, tokenizer=tokenizer):\n",
    "    input_ids = []\n",
    "    attention_mask = []\n",
    "    \n",
    "    for text in texts.tolist():\n",
    "        token = tokenizer(text, \n",
    "                          add_special_tokens=True, \n",
    "                          max_length=MAX_LENGTH, \n",
    "                          return_attention_mask=True, \n",
    "                          return_tensors=\"np\", \n",
    "                          truncation=True, \n",
    "                          padding='max_length')\n",
    "        input_ids.append(token['input_ids'][0])\n",
    "        attention_mask.append(token['attention_mask'][0])\n",
    "    \n",
    "    return np.array(input_ids, dtype=\"int32\"), np.array(attention_mask, dtype=\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec47d758",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-31T21:30:42.244312Z",
     "iopub.status.busy": "2022-10-31T21:30:42.242880Z",
     "iopub.status.idle": "2022-10-31T21:30:42.248116Z",
     "shell.execute_reply": "2022-10-31T21:30:42.247226Z"
    },
    "papermill": {
     "duration": 0.014737,
     "end_time": "2022-10-31T21:30:42.250108",
     "exception": false,
     "start_time": "2022-10-31T21:30:42.235371",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_dataset(df):\n",
    "    inputs = deberta_encode(df['full_text'])\n",
    "    targets = np.array(df[TARGET_COLS], dtype=\"float32\")\n",
    "    return inputs, targets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f67103",
   "metadata": {
    "papermill": {
     "duration": 0.006449,
     "end_time": "2022-10-31T21:30:42.263504",
     "exception": false,
     "start_time": "2022-10-31T21:30:42.257055",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model\n",
    "\n",
    "## MeanPool\n",
    "\n",
    "Instead of using '[CLS]' token, MeanPool method averaging one layer of hidden states along the sequence axis with masking out padding tokens.\n",
    "\n",
    "## WeightedLayerPool\n",
    "\n",
    "WeightedLayerPool uses a set of trainable weights to average a set of hidden states from transformer backbone. I use a Dense layer with constraint to implement it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "165c0a50",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-31T21:30:42.278388Z",
     "iopub.status.busy": "2022-10-31T21:30:42.277627Z",
     "iopub.status.idle": "2022-10-31T21:30:42.283224Z",
     "shell.execute_reply": "2022-10-31T21:30:42.282270Z"
    },
    "papermill": {
     "duration": 0.015035,
     "end_time": "2022-10-31T21:30:42.285152",
     "exception": false,
     "start_time": "2022-10-31T21:30:42.270117",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MeanPool(tf.keras.layers.Layer):\n",
    "    def call(self, inputs, mask=None):\n",
    "        broadcast_mask = tf.expand_dims(tf.cast(mask, \"float32\"), -1)\n",
    "        embedding_sum = tf.reduce_sum(inputs * broadcast_mask, axis=1)\n",
    "        mask_sum = tf.reduce_sum(broadcast_mask, axis=1)\n",
    "        mask_sum = tf.math.maximum(mask_sum, tf.constant([1e-9]))\n",
    "        return embedding_sum / mask_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50dcd97d",
   "metadata": {
    "papermill": {
     "duration": 0.006439,
     "end_time": "2022-10-31T21:30:42.298166",
     "exception": false,
     "start_time": "2022-10-31T21:30:42.291727",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "WeightedLayerPool weights constraints: softmax to push sum(w) to be 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2984406",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-31T21:30:42.313323Z",
     "iopub.status.busy": "2022-10-31T21:30:42.312543Z",
     "iopub.status.idle": "2022-10-31T21:30:42.317605Z",
     "shell.execute_reply": "2022-10-31T21:30:42.316789Z"
    },
    "papermill": {
     "duration": 0.014745,
     "end_time": "2022-10-31T21:30:42.319633",
     "exception": false,
     "start_time": "2022-10-31T21:30:42.304888",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class WeightsSumOne(tf.keras.constraints.Constraint):\n",
    "    def __call__(self, w):\n",
    "        return tf.nn.softmax(w, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d17723",
   "metadata": {
    "papermill": {
     "duration": 0.006751,
     "end_time": "2022-10-31T21:30:42.333298",
     "exception": false,
     "start_time": "2022-10-31T21:30:42.326547",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model Design Choice\n",
    "\n",
    "Although there are many ways to get your final representations, I choose to take the last 4 layers hidden states of DeBERTa, take MeanPool of them to gather information along the sequence axis, then take WeightedLayerPool with a set of trainable weights to gather information along the depth axis of the model, then finally a regression head."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "70b8d80f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-31T21:30:42.349547Z",
     "iopub.status.busy": "2022-10-31T21:30:42.347876Z",
     "iopub.status.idle": "2022-10-31T21:30:42.356317Z",
     "shell.execute_reply": "2022-10-31T21:30:42.355442Z"
    },
    "papermill": {
     "duration": 0.018224,
     "end_time": "2022-10-31T21:30:42.358305",
     "exception": false,
     "start_time": "2022-10-31T21:30:42.340081",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    input_ids = tf.keras.layers.Input(\n",
    "        shape=(MAX_LENGTH,), dtype=tf.int32, name=\"input_ids\"\n",
    "    )\n",
    "    \n",
    "    attention_masks = tf.keras.layers.Input(\n",
    "        shape=(MAX_LENGTH,), dtype=tf.int32, name=\"attention_masks\"\n",
    "    )\n",
    "   \n",
    "    deberta_model = transformers.TFAutoModel.from_pretrained(DEBERTA_MODEL, config=cfg)\n",
    "    deberta_output = deberta_model.deberta(\n",
    "        input_ids, attention_mask=attention_masks\n",
    "    )\n",
    "    hidden_states = deberta_output.hidden_states\n",
    "    \n",
    "    stack_meanpool = tf.stack(\n",
    "        [MeanPool()(hidden_s, mask=attention_masks) for hidden_s in hidden_states[-4:]], \n",
    "        axis=2)\n",
    "    \n",
    "    weighted_layer_pool = layers.Dense(1,\n",
    "                                       use_bias=False,\n",
    "                                       kernel_constraint=WeightsSumOne())(stack_meanpool)\n",
    "    \n",
    "    weighted_layer_pool = tf.squeeze(weighted_layer_pool, axis=-1)\n",
    "    \n",
    "    x = layers.Dense(6, activation='linear')(weighted_layer_pool)\n",
    "    #output = layers.Rescaling(scale=4.0, offset=1.0)(x)\n",
    "    model = tf.keras.Model(inputs=[input_ids, attention_masks], outputs=x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b8eebe5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-31T21:30:42.374047Z",
     "iopub.status.busy": "2022-10-31T21:30:42.373023Z",
     "iopub.status.idle": "2022-10-31T21:31:08.072365Z",
     "shell.execute_reply": "2022-10-31T21:31:08.070242Z"
    },
    "papermill": {
     "duration": 25.709803,
     "end_time": "2022-10-31T21:31:08.074811",
     "exception": false,
     "start_time": "2022-10-31T21:30:42.365008",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-31 21:30:44.047461: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-31 21:30:44.048542: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-31 21:30:44.049225: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-31 21:30:44.050086: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-31 21:30:44.050373: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-31 21:30:44.051186: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-31 21:30:44.051847: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-31 21:30:48.949204: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-31 21:30:48.950104: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-31 21:30:48.950821: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-31 21:30:48.951484: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15043 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_ids (InputLayer)          [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "attention_masks (InputLayer)    [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "deberta (TFDebertaV2MainLayer)  TFBaseModelOutput(la 183831552   input_ids[0][0]                  \n",
      "                                                                 attention_masks[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "mean_pool (MeanPool)            (None, 768)          0           deberta[0][9]                    \n",
      "                                                                 attention_masks[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "mean_pool_1 (MeanPool)          (None, 768)          0           deberta[0][10]                   \n",
      "                                                                 attention_masks[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "mean_pool_2 (MeanPool)          (None, 768)          0           deberta[0][11]                   \n",
      "                                                                 attention_masks[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "mean_pool_3 (MeanPool)          (None, 768)          0           deberta[0][12]                   \n",
      "                                                                 attention_masks[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf.stack (TFOpLambda)           (None, 768, 4)       0           mean_pool[0][0]                  \n",
      "                                                                 mean_pool_1[0][0]                \n",
      "                                                                 mean_pool_2[0][0]                \n",
      "                                                                 mean_pool_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 768, 1)       4           tf.stack[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.squeeze (TFOpLambd (None, 768)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 6)            4614        tf.compat.v1.squeeze[0][0]       \n",
      "==================================================================================================\n",
      "Total params: 183,836,170\n",
      "Trainable params: 183,836,170\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "model = get_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6647e6a8",
   "metadata": {
    "papermill": {
     "duration": 0.007168,
     "end_time": "2022-10-31T21:31:08.089643",
     "exception": false,
     "start_time": "2022-10-31T21:31:08.082475",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 5 Folds Training Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa737bb7",
   "metadata": {
    "papermill": {
     "duration": 0.007224,
     "end_time": "2022-10-31T21:31:08.104551",
     "exception": false,
     "start_time": "2022-10-31T21:31:08.097327",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "When training model, I employ an approximation of layer-wise learning rate decay. That is a MultiOptimizer with initial learning rate 1e-5 for DeBERTa backbone and initial learning rate 1e-4 for the rest of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b10c6b90",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-31T21:31:08.121046Z",
     "iopub.status.busy": "2022-10-31T21:31:08.120488Z",
     "iopub.status.idle": "2022-11-01T01:07:01.284270Z",
     "shell.execute_reply": "2022-11-01T01:07:01.283258Z"
    },
    "papermill": {
     "duration": 12953.17789,
     "end_time": "2022-11-01T01:07:01.289706",
     "exception": false,
     "start_time": "2022-10-31T21:31:08.111816",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------FOLD 0 ------------\n",
      "Data prepared.\n",
      "Training data input_ids shape: (3129, 512) dtype: int32\n",
      "Training data attention_mask shape: (3129, 512) dtype: int32\n",
      "Training data targets shape: (3129, 6) dtype: float32\n",
      "Validation data input_ids shape: (782, 512) dtype: int32\n",
      "Validation data attention_mask shape: (782, 512) dtype: int32\n",
      "Validation data targets shape: (782, 6) dtype: float32\n",
      "Model prepared.\n",
      "Start training...\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-31 21:31:26.822326: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "783/783 [==============================] - 422s 482ms/step - loss: 0.4319 - root_mean_squared_error: 0.6572 - val_loss: 0.2210 - val_root_mean_squared_error: 0.4701\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.22103, saving model to best_model_fold0.h5\n",
      "Epoch 2/10\n",
      "783/783 [==============================] - 371s 473ms/step - loss: 0.2168 - root_mean_squared_error: 0.4656 - val_loss: 0.2188 - val_root_mean_squared_error: 0.4677\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.22103 to 0.21876, saving model to best_model_fold0.h5\n",
      "Epoch 3/10\n",
      "783/783 [==============================] - 371s 474ms/step - loss: 0.1973 - root_mean_squared_error: 0.4442 - val_loss: 0.2059 - val_root_mean_squared_error: 0.4537\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.21876 to 0.20588, saving model to best_model_fold0.h5\n",
      "Epoch 4/10\n",
      "783/783 [==============================] - 371s 474ms/step - loss: 0.1856 - root_mean_squared_error: 0.4308 - val_loss: 0.2088 - val_root_mean_squared_error: 0.4569\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.20588\n",
      "Epoch 5/10\n",
      "783/783 [==============================] - 371s 474ms/step - loss: 0.1778 - root_mean_squared_error: 0.4217 - val_loss: 0.2059 - val_root_mean_squared_error: 0.4537\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.20588 to 0.20587, saving model to best_model_fold0.h5\n",
      "Epoch 6/10\n",
      "783/783 [==============================] - 371s 474ms/step - loss: 0.1734 - root_mean_squared_error: 0.4165 - val_loss: 0.2090 - val_root_mean_squared_error: 0.4572\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.20587\n",
      "Epoch 00006: early stopping\n",
      "Training finished.\n",
      "\n",
      "-----------FOLD 1 ------------\n",
      "Data prepared.\n",
      "Training data input_ids shape: (3128, 512) dtype: int32\n",
      "Training data attention_mask shape: (3128, 512) dtype: int32\n",
      "Training data targets shape: (3128, 6) dtype: float32\n",
      "Validation data input_ids shape: (783, 512) dtype: int32\n",
      "Validation data attention_mask shape: (783, 512) dtype: int32\n",
      "Validation data targets shape: (783, 6) dtype: float32\n",
      "Model prepared.\n",
      "Start training...\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 390s 452ms/step - loss: 0.4206 - root_mean_squared_error: 0.6485 - val_loss: 0.2177 - val_root_mean_squared_error: 0.4666\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.21772, saving model to best_model_fold1.h5\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 346s 442ms/step - loss: 0.2068 - root_mean_squared_error: 0.4548 - val_loss: 0.2124 - val_root_mean_squared_error: 0.4609\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.21772 to 0.21244, saving model to best_model_fold1.h5\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 346s 442ms/step - loss: 0.1847 - root_mean_squared_error: 0.4298 - val_loss: 0.2170 - val_root_mean_squared_error: 0.4659\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.21244\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 346s 442ms/step - loss: 0.1734 - root_mean_squared_error: 0.4164 - val_loss: 0.2154 - val_root_mean_squared_error: 0.4641\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.21244\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 346s 442ms/step - loss: 0.1634 - root_mean_squared_error: 0.4042 - val_loss: 0.2141 - val_root_mean_squared_error: 0.4627\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.21244\n",
      "Epoch 00005: early stopping\n",
      "Training finished.\n",
      "\n",
      "-----------FOLD 2 ------------\n",
      "Data prepared.\n",
      "Training data input_ids shape: (3129, 512) dtype: int32\n",
      "Training data attention_mask shape: (3129, 512) dtype: int32\n",
      "Training data targets shape: (3129, 6) dtype: float32\n",
      "Validation data input_ids shape: (782, 512) dtype: int32\n",
      "Validation data attention_mask shape: (782, 512) dtype: int32\n",
      "Validation data targets shape: (782, 6) dtype: float32\n",
      "Model prepared.\n",
      "Start training...\n",
      "Epoch 1/10\n",
      "783/783 [==============================] - 423s 483ms/step - loss: 0.4176 - root_mean_squared_error: 0.6462 - val_loss: 0.2373 - val_root_mean_squared_error: 0.4871\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.23728, saving model to best_model_fold2.h5\n",
      "Epoch 2/10\n",
      "783/783 [==============================] - 371s 474ms/step - loss: 0.2117 - root_mean_squared_error: 0.4601 - val_loss: 0.2230 - val_root_mean_squared_error: 0.4723\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.23728 to 0.22305, saving model to best_model_fold2.h5\n",
      "Epoch 3/10\n",
      "783/783 [==============================] - 371s 474ms/step - loss: 0.1944 - root_mean_squared_error: 0.4409 - val_loss: 0.2486 - val_root_mean_squared_error: 0.4986\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.22305\n",
      "Epoch 4/10\n",
      "783/783 [==============================] - 371s 473ms/step - loss: 0.1820 - root_mean_squared_error: 0.4267 - val_loss: 0.2233 - val_root_mean_squared_error: 0.4725\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.22305\n",
      "Epoch 5/10\n",
      "783/783 [==============================] - 371s 474ms/step - loss: 0.1753 - root_mean_squared_error: 0.4187 - val_loss: 0.2244 - val_root_mean_squared_error: 0.4738\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.22305\n",
      "Epoch 00005: early stopping\n",
      "Training finished.\n",
      "\n",
      "-----------FOLD 3 ------------\n",
      "Data prepared.\n",
      "Training data input_ids shape: (3129, 512) dtype: int32\n",
      "Training data attention_mask shape: (3129, 512) dtype: int32\n",
      "Training data targets shape: (3129, 6) dtype: float32\n",
      "Validation data input_ids shape: (782, 512) dtype: int32\n",
      "Validation data attention_mask shape: (782, 512) dtype: int32\n",
      "Validation data targets shape: (782, 6) dtype: float32\n",
      "Model prepared.\n",
      "Start training...\n",
      "Epoch 1/10\n",
      "783/783 [==============================] - 425s 484ms/step - loss: 0.4485 - root_mean_squared_error: 0.6697 - val_loss: 0.2362 - val_root_mean_squared_error: 0.4860\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.23624, saving model to best_model_fold3.h5\n",
      "Epoch 2/10\n",
      "783/783 [==============================] - 372s 475ms/step - loss: 0.2110 - root_mean_squared_error: 0.4594 - val_loss: 0.2191 - val_root_mean_squared_error: 0.4681\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.23624 to 0.21908, saving model to best_model_fold3.h5\n",
      "Epoch 3/10\n",
      "783/783 [==============================] - 372s 475ms/step - loss: 0.1914 - root_mean_squared_error: 0.4375 - val_loss: 0.2113 - val_root_mean_squared_error: 0.4597\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.21908 to 0.21129, saving model to best_model_fold3.h5\n",
      "Epoch 4/10\n",
      "783/783 [==============================] - 372s 475ms/step - loss: 0.1790 - root_mean_squared_error: 0.4231 - val_loss: 0.2118 - val_root_mean_squared_error: 0.4603\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.21129\n",
      "Epoch 5/10\n",
      "783/783 [==============================] - 372s 475ms/step - loss: 0.1718 - root_mean_squared_error: 0.4145 - val_loss: 0.2106 - val_root_mean_squared_error: 0.4589\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.21129 to 0.21056, saving model to best_model_fold3.h5\n",
      "Epoch 6/10\n",
      "783/783 [==============================] - 372s 476ms/step - loss: 0.1671 - root_mean_squared_error: 0.4087 - val_loss: 0.2110 - val_root_mean_squared_error: 0.4594\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.21056\n",
      "Epoch 7/10\n",
      "783/783 [==============================] - 372s 475ms/step - loss: 0.1641 - root_mean_squared_error: 0.4050 - val_loss: 0.2114 - val_root_mean_squared_error: 0.4598\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.21056\n",
      "Epoch 8/10\n",
      "783/783 [==============================] - 371s 474ms/step - loss: 0.1626 - root_mean_squared_error: 0.4032 - val_loss: 0.2114 - val_root_mean_squared_error: 0.4598\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.21056\n",
      "Epoch 00008: early stopping\n",
      "Training finished.\n",
      "\n",
      "-----------FOLD 4 ------------\n",
      "Data prepared.\n",
      "Training data input_ids shape: (3129, 512) dtype: int32\n",
      "Training data attention_mask shape: (3129, 512) dtype: int32\n",
      "Training data targets shape: (3129, 6) dtype: float32\n",
      "Validation data input_ids shape: (782, 512) dtype: int32\n",
      "Validation data attention_mask shape: (782, 512) dtype: int32\n",
      "Validation data targets shape: (782, 6) dtype: float32\n",
      "Model prepared.\n",
      "Start training...\n",
      "Epoch 1/10\n",
      "783/783 [==============================] - 418s 480ms/step - loss: 0.4020 - root_mean_squared_error: 0.6341 - val_loss: 0.2149 - val_root_mean_squared_error: 0.4636\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.21488, saving model to best_model_fold4.h5\n",
      "Epoch 2/10\n",
      "783/783 [==============================] - 370s 472ms/step - loss: 0.2056 - root_mean_squared_error: 0.4535 - val_loss: 0.2148 - val_root_mean_squared_error: 0.4634\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.21488 to 0.21476, saving model to best_model_fold4.h5\n",
      "Epoch 3/10\n",
      "783/783 [==============================] - 370s 472ms/step - loss: 0.1864 - root_mean_squared_error: 0.4317 - val_loss: 0.2116 - val_root_mean_squared_error: 0.4600\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.21476 to 0.21164, saving model to best_model_fold4.h5\n",
      "Epoch 4/10\n",
      "783/783 [==============================] - 369s 472ms/step - loss: 0.1724 - root_mean_squared_error: 0.4152 - val_loss: 0.2079 - val_root_mean_squared_error: 0.4559\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.21164 to 0.20787, saving model to best_model_fold4.h5\n",
      "Epoch 5/10\n",
      "783/783 [==============================] - 369s 472ms/step - loss: 0.1645 - root_mean_squared_error: 0.4056 - val_loss: 0.2083 - val_root_mean_squared_error: 0.4564\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.20787\n",
      "Epoch 6/10\n",
      "783/783 [==============================] - 370s 472ms/step - loss: 0.1588 - root_mean_squared_error: 0.3985 - val_loss: 0.2076 - val_root_mean_squared_error: 0.4556\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.20787 to 0.20760, saving model to best_model_fold4.h5\n",
      "Epoch 7/10\n",
      "783/783 [==============================] - 370s 472ms/step - loss: 0.1560 - root_mean_squared_error: 0.3950 - val_loss: 0.2055 - val_root_mean_squared_error: 0.4533\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.20760 to 0.20550, saving model to best_model_fold4.h5\n",
      "Epoch 8/10\n",
      "783/783 [==============================] - 369s 472ms/step - loss: 0.1543 - root_mean_squared_error: 0.3927 - val_loss: 0.2068 - val_root_mean_squared_error: 0.4547\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.20550\n",
      "Epoch 9/10\n",
      "783/783 [==============================] - 370s 472ms/step - loss: 0.1534 - root_mean_squared_error: 0.3916 - val_loss: 0.2062 - val_root_mean_squared_error: 0.4541\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.20550\n",
      "Epoch 10/10\n",
      "783/783 [==============================] - 369s 472ms/step - loss: 0.1528 - root_mean_squared_error: 0.3909 - val_loss: 0.2059 - val_root_mean_squared_error: 0.4538\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.20550\n",
      "Epoch 00010: early stopping\n",
      "Training finished.\n"
     ]
    }
   ],
   "source": [
    "valid_rmses = []\n",
    "for fold in range(N_FOLD):\n",
    "    print(f'\\n-----------FOLD {fold} ------------')\n",
    "    \n",
    "    #Create dataset\n",
    "    train_df = df[df['fold'] != fold].reset_index(drop=True)\n",
    "    valid_df = df[df['fold'] == fold].reset_index(drop=True)\n",
    "    train_dataset = get_dataset(train_df)\n",
    "    valid_dataset = get_dataset(valid_df)\n",
    "    \n",
    "    print('Data prepared.')\n",
    "    print(f'Training data input_ids shape: {train_dataset[0][0].shape} dtype: {train_dataset[0][0].dtype}') \n",
    "    print(f'Training data attention_mask shape: {train_dataset[0][1].shape} dtype: {train_dataset[0][1].dtype}')\n",
    "    print(f'Training data targets shape: {train_dataset[1].shape} dtype: {train_dataset[1].dtype}')\n",
    "    print(f'Validation data input_ids shape: {valid_dataset[0][0].shape} dtype: {valid_dataset[0][0].dtype}')\n",
    "    print(f'Validation data attention_mask shape: {valid_dataset[0][1].shape} dtype: {valid_dataset[0][1].dtype}')\n",
    "    print(f'Validation data targets shape: {valid_dataset[1].shape} dtype: {valid_dataset[1].dtype}')\n",
    "    \n",
    "    #Create model\n",
    "    tf.keras.backend.clear_session()\n",
    "    model = get_model()\n",
    "    \n",
    "    #Compile model with an approximation of layer-wise learning rate decay\n",
    "    LR_SCH_DECAY_STEPS = 2 * len(train_df) // BATCH_SIZE\n",
    "    lr_schedule_1 = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "        initial_learning_rate=1e-5, \n",
    "        decay_steps=LR_SCH_DECAY_STEPS, \n",
    "        decay_rate=0.3)\n",
    "    lr_schedule_2 = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "        initial_learning_rate=1e-4, \n",
    "        decay_steps=LR_SCH_DECAY_STEPS, \n",
    "        decay_rate=0.3)\n",
    "    optimizers = [tf.keras.optimizers.Adam(learning_rate=lr_schedule_1),\n",
    "                  tf.keras.optimizers.Adam(learning_rate=lr_schedule_2)]\n",
    "    optimizers_and_layers = [(optimizers[0], model.layers[:-4]),\n",
    "                             (optimizers[1], model.layers[-4:]),]\n",
    "    optimizer = tfa.optimizers.MultiOptimizer(optimizers_and_layers)\n",
    "\n",
    "    model.compile(optimizer=optimizer,\n",
    "                 loss='MeanSquaredError',\n",
    "                 metrics=[tf.keras.metrics.RootMeanSquaredError()],\n",
    "                 )\n",
    "    print('Model prepared.')\n",
    "    \n",
    "    #Training model\n",
    "    print('Start training...')\n",
    "    callbacks = [\n",
    "    tf.keras.callbacks.ModelCheckpoint(f\"best_model_fold{fold}.h5\",\n",
    "                                       monitor=\"val_loss\",\n",
    "                                       mode=\"min\",\n",
    "                                       save_best_only=True,\n",
    "                                       verbose=1,\n",
    "                                       save_weights_only=True,),\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                     min_delta=1e-5, \n",
    "                                     patience=3, \n",
    "                                     verbose=1,\n",
    "                                     mode='min',)\n",
    "    ]\n",
    "    history = model.fit(x=train_dataset[0],\n",
    "                        y=train_dataset[1],\n",
    "                        validation_data=valid_dataset, \n",
    "                        epochs=10,\n",
    "                        shuffle=True,\n",
    "                        batch_size=BATCH_SIZE,\n",
    "                        callbacks=callbacks\n",
    "                       )\n",
    "    \n",
    "    valid_rmses.append(np.min(history.history['val_root_mean_squared_error']))\n",
    "    print('Training finished.')\n",
    "    del train_dataset, valid_dataset, train_df, valid_df\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f9922a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-01T01:07:04.319811Z",
     "iopub.status.busy": "2022-11-01T01:07:04.319086Z",
     "iopub.status.idle": "2022-11-01T01:07:04.372771Z",
     "shell.execute_reply": "2022-11-01T01:07:04.371668Z"
    },
    "papermill": {
     "duration": 1.569812,
     "end_time": "2022-11-01T01:07:04.375131",
     "exception": false,
     "start_time": "2022-11-01T01:07:02.805319",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 Folds validation RMSE:\n",
      "[0.45372921228408813, 0.46091246604919434, 0.4722799062728882, 0.458873450756073, 0.45331820845603943]\n",
      "Local CV Average score: 0.45982264876365664\n"
     ]
    }
   ],
   "source": [
    "print(f'{len(valid_rmses)} Folds validation RMSE:\\n{valid_rmses}')\n",
    "print(f'Local CV Average score: {np.mean(valid_rmses)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6ebb1d",
   "metadata": {
    "papermill": {
     "duration": 1.505898,
     "end_time": "2022-11-01T01:07:07.534246",
     "exception": false,
     "start_time": "2022-11-01T01:07:06.028348",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Inference and Submission\n",
    "\n",
    "Load test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8ce20d9b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-01T01:07:10.551150Z",
     "iopub.status.busy": "2022-11-01T01:07:10.550236Z",
     "iopub.status.idle": "2022-11-01T01:07:10.573360Z",
     "shell.execute_reply": "2022-11-01T01:07:10.572460Z"
    },
    "papermill": {
     "duration": 1.52905,
     "end_time": "2022-11-01T01:07:10.575519",
     "exception": false,
     "start_time": "2022-11-01T01:07:09.046469",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>full_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000C359D63E</td>\n",
       "      <td>when a person has no experience on a job their...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000BAD50D026</td>\n",
       "      <td>Do you think students would benefit from being...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00367BB2546B</td>\n",
       "      <td>Thomas Jefferson once states that \"it is wonde...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        text_id                                          full_text\n",
       "0  0000C359D63E  when a person has no experience on a job their...\n",
       "1  000BAD50D026  Do you think students would benefit from being...\n",
       "2  00367BB2546B  Thomas Jefferson once states that \"it is wonde..."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv('../input/feedback-prize-english-language-learning/test.csv')\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "111032a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-01T01:07:13.692556Z",
     "iopub.status.busy": "2022-11-01T01:07:13.692091Z",
     "iopub.status.idle": "2022-11-01T01:07:13.714108Z",
     "shell.execute_reply": "2022-11-01T01:07:13.713259Z"
    },
    "papermill": {
     "duration": 1.633618,
     "end_time": "2022-11-01T01:07:13.716295",
     "exception": false,
     "start_time": "2022-11-01T01:07:12.082677",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_dataset = deberta_encode(test_df['full_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7abb36d8",
   "metadata": {
    "papermill": {
     "duration": 1.742677,
     "end_time": "2022-11-01T01:07:17.333666",
     "exception": false,
     "start_time": "2022-11-01T01:07:15.590989",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 5 Folds ensemble prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "11259a7e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-01T01:07:20.271955Z",
     "iopub.status.busy": "2022-11-01T01:07:20.271579Z",
     "iopub.status.idle": "2022-11-01T01:09:28.908950Z",
     "shell.execute_reply": "2022-11-01T01:09:28.907861Z"
    },
    "papermill": {
     "duration": 130.159709,
     "end_time": "2022-11-01T01:09:28.916325",
     "exception": false,
     "start_time": "2022-11-01T01:07:18.756616",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 0 inference...\n",
      "\n",
      "Fold 1 inference...\n",
      "\n",
      "Fold 2 inference...\n",
      "\n",
      "Fold 3 inference...\n",
      "\n",
      "Fold 4 inference...\n"
     ]
    }
   ],
   "source": [
    "fold_preds = []\n",
    "for fold in range(N_FOLD):\n",
    "    tf.keras.backend.clear_session()\n",
    "    model = get_model()\n",
    "    model.load_weights(f'best_model_fold{fold}.h5')\n",
    "    print(f'\\nFold {fold} inference...')\n",
    "    pred = model.predict(test_dataset, batch_size=BATCH_SIZE)\n",
    "    fold_preds.append(pred)\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a540a3d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-01T01:09:31.869358Z",
     "iopub.status.busy": "2022-11-01T01:09:31.868984Z",
     "iopub.status.idle": "2022-11-01T01:09:31.894566Z",
     "shell.execute_reply": "2022-11-01T01:09:31.893467Z"
    },
    "papermill": {
     "duration": 1.466282,
     "end_time": "2022-11-01T01:09:31.897250",
     "exception": false,
     "start_time": "2022-11-01T01:09:30.430968",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "preds = np.mean(fold_preds, axis=0)\n",
    "preds = np.clip(preds, 1, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e3014944",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-01T01:09:34.928141Z",
     "iopub.status.busy": "2022-11-01T01:09:34.927778Z",
     "iopub.status.idle": "2022-11-01T01:09:34.936505Z",
     "shell.execute_reply": "2022-11-01T01:09:34.935449Z"
    },
    "papermill": {
     "duration": 1.527213,
     "end_time": "2022-11-01T01:09:34.938753",
     "exception": false,
     "start_time": "2022-11-01T01:09:33.411540",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub_df = pd.concat([test_df[['text_id']], pd.DataFrame(preds, columns=TARGET_COLS)], axis=1)\n",
    "sub_df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "46c32551",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-01T01:09:37.926939Z",
     "iopub.status.busy": "2022-11-01T01:09:37.926576Z",
     "iopub.status.idle": "2022-11-01T01:09:37.939915Z",
     "shell.execute_reply": "2022-11-01T01:09:37.938732Z"
    },
    "papermill": {
     "duration": 1.571928,
     "end_time": "2022-11-01T01:09:37.942063",
     "exception": false,
     "start_time": "2022-11-01T01:09:36.370135",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>cohesion</th>\n",
       "      <th>syntax</th>\n",
       "      <th>vocabulary</th>\n",
       "      <th>phraseology</th>\n",
       "      <th>grammar</th>\n",
       "      <th>conventions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000C359D63E</td>\n",
       "      <td>2.958955</td>\n",
       "      <td>2.778274</td>\n",
       "      <td>3.101005</td>\n",
       "      <td>2.931064</td>\n",
       "      <td>2.712532</td>\n",
       "      <td>2.725166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000BAD50D026</td>\n",
       "      <td>2.593868</td>\n",
       "      <td>2.408805</td>\n",
       "      <td>2.656760</td>\n",
       "      <td>2.336524</td>\n",
       "      <td>2.128315</td>\n",
       "      <td>2.608301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00367BB2546B</td>\n",
       "      <td>3.544802</td>\n",
       "      <td>3.359350</td>\n",
       "      <td>3.521230</td>\n",
       "      <td>3.456447</td>\n",
       "      <td>3.348444</td>\n",
       "      <td>3.287421</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        text_id  cohesion    syntax  vocabulary  phraseology   grammar  \\\n",
       "0  0000C359D63E  2.958955  2.778274    3.101005     2.931064  2.712532   \n",
       "1  000BAD50D026  2.593868  2.408805    2.656760     2.336524  2.128315   \n",
       "2  00367BB2546B  3.544802  3.359350    3.521230     3.456447  3.348444   \n",
       "\n",
       "   conventions  \n",
       "0     2.725166  \n",
       "1     2.608301  \n",
       "2     3.287421  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2290ff",
   "metadata": {
    "papermill": {
     "duration": 1.474783,
     "end_time": "2022-11-01T01:09:41.082840",
     "exception": false,
     "start_time": "2022-11-01T01:09:39.608057",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 13162.18683,
   "end_time": "2022-11-01T01:09:46.566994",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-10-31T21:30:24.380164",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
