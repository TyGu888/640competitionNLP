{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64946ca6",
   "metadata": {
    "papermill": {
     "duration": 0.006245,
     "end_time": "2022-11-27T12:51:20.869450",
     "exception": false,
     "start_time": "2022-11-27T12:51:20.863205",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# DeBERTa LLRD + LastLayerReinit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654adf8b",
   "metadata": {
    "papermill": {
     "duration": 0.007527,
     "end_time": "2022-11-27T12:51:20.856681",
     "exception": false,
     "start_time": "2022-11-27T12:51:20.849154",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef1a0aaa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-27T12:51:20.884035Z",
     "iopub.status.busy": "2022-11-27T12:51:20.883329Z",
     "iopub.status.idle": "2022-11-27T12:51:27.444935Z",
     "shell.execute_reply": "2022-11-27T12:51:27.443960Z"
    },
    "papermill": {
     "duration": 6.571864,
     "end_time": "2022-11-27T12:51:27.447559",
     "exception": false,
     "start_time": "2022-11-27T12:51:20.875695",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF version: 2.6.4\n",
      "transformers version: 4.20.1\n"
     ]
    }
   ],
   "source": [
    "import os, gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "print(f'TF version: {tf.__version__}')\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import transformers\n",
    "print(f'transformers version: {transformers.__version__}')\n",
    "from transformers import logging as hf_logging\n",
    "hf_logging.set_verbosity_error()\n",
    "\n",
    "import sys\n",
    "sys.path.append('../input/iterativestratification')\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7566904",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-27T12:51:27.462285Z",
     "iopub.status.busy": "2022-11-27T12:51:27.461568Z",
     "iopub.status.idle": "2022-11-27T12:51:27.468107Z",
     "shell.execute_reply": "2022-11-27T12:51:27.467257Z"
    },
    "papermill": {
     "duration": 0.01576,
     "end_time": "2022-11-27T12:51:27.470043",
     "exception": false,
     "start_time": "2022-11-27T12:51:27.454283",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_seed(seed=1225):\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "#     os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "set_seed(1225)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faefba23",
   "metadata": {
    "papermill": {
     "duration": 0.006026,
     "end_time": "2022-11-27T12:51:27.482230",
     "exception": false,
     "start_time": "2022-11-27T12:51:27.476204",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61c18173",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-27T12:51:27.496405Z",
     "iopub.status.busy": "2022-11-27T12:51:27.495580Z",
     "iopub.status.idle": "2022-11-27T12:51:27.727849Z",
     "shell.execute_reply": "2022-11-27T12:51:27.726537Z"
    },
    "papermill": {
     "duration": 0.24188,
     "end_time": "2022-11-27T12:51:27.730405",
     "exception": false,
     "start_time": "2022-11-27T12:51:27.488525",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>cohesion</th>\n",
       "      <th>syntax</th>\n",
       "      <th>vocabulary</th>\n",
       "      <th>phraseology</th>\n",
       "      <th>grammar</th>\n",
       "      <th>conventions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0016926B079C</td>\n",
       "      <td>I think that students would benefit from learn...</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0022683E9EA5</td>\n",
       "      <td>When a problem is a change you have to let it ...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00299B378633</td>\n",
       "      <td>Dear, Principal\\n\\nIf u change the school poli...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>003885A45F42</td>\n",
       "      <td>The best time in life is when you become yours...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0049B1DF5CCC</td>\n",
       "      <td>Small act of kindness can impact in other peop...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        text_id                                          full_text  cohesion  \\\n",
       "0  0016926B079C  I think that students would benefit from learn...       3.5   \n",
       "1  0022683E9EA5  When a problem is a change you have to let it ...       2.5   \n",
       "2  00299B378633  Dear, Principal\\n\\nIf u change the school poli...       3.0   \n",
       "3  003885A45F42  The best time in life is when you become yours...       4.5   \n",
       "4  0049B1DF5CCC  Small act of kindness can impact in other peop...       2.5   \n",
       "\n",
       "   syntax  vocabulary  phraseology  grammar  conventions  \n",
       "0     3.5         3.0          3.0      4.0          3.0  \n",
       "1     2.5         3.0          2.0      2.0          2.5  \n",
       "2     3.5         3.0          3.0      3.0          2.5  \n",
       "3     4.5         4.5          4.5      4.0          5.0  \n",
       "4     3.0         3.0          3.0      2.5          2.5  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------DataFrame Summary---------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3911 entries, 0 to 3910\n",
      "Data columns (total 8 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   text_id      3911 non-null   object \n",
      " 1   full_text    3911 non-null   object \n",
      " 2   cohesion     3911 non-null   float64\n",
      " 3   syntax       3911 non-null   float64\n",
      " 4   vocabulary   3911 non-null   float64\n",
      " 5   phraseology  3911 non-null   float64\n",
      " 6   grammar      3911 non-null   float64\n",
      " 7   conventions  3911 non-null   float64\n",
      "dtypes: float64(6), object(2)\n",
      "memory usage: 244.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../input/feedback-prize-english-language-learning/train.csv')\n",
    "display(df.head())\n",
    "print('\\n---------DataFrame Summary---------')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75448ffc",
   "metadata": {
    "papermill": {
     "duration": 0.006435,
     "end_time": "2022-11-27T12:51:27.743698",
     "exception": false,
     "start_time": "2022-11-27T12:51:27.737263",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## CV Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0a7562c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-27T12:51:27.759655Z",
     "iopub.status.busy": "2022-11-27T12:51:27.758734Z",
     "iopub.status.idle": "2022-11-27T12:51:27.890223Z",
     "shell.execute_reply": "2022-11-27T12:51:27.889130Z"
    },
    "papermill": {
     "duration": 0.141444,
     "end_time": "2022-11-27T12:51:27.892679",
     "exception": false,
     "start_time": "2022-11-27T12:51:27.751235",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    783\n",
       "0    782\n",
       "4    782\n",
       "3    782\n",
       "2    782\n",
       "Name: fold, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_FOLD = 5\n",
    "TARGET_COLS = ['cohesion', 'syntax', 'vocabulary', 'phraseology', 'grammar', 'conventions']\n",
    "\n",
    "skf = MultilabelStratifiedKFold(n_splits=N_FOLD, shuffle=True, random_state=42)\n",
    "for n, (train_index, val_index) in enumerate(skf.split(df, df[TARGET_COLS])):\n",
    "    df.loc[val_index, 'fold'] = int(n)\n",
    "df['fold'] = df['fold'].astype(int)\n",
    "df['fold'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42880bcd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-27T12:51:27.908014Z",
     "iopub.status.busy": "2022-11-27T12:51:27.907411Z",
     "iopub.status.idle": "2022-11-27T12:51:28.055579Z",
     "shell.execute_reply": "2022-11-27T12:51:28.054590Z"
    },
    "papermill": {
     "duration": 0.158662,
     "end_time": "2022-11-27T12:51:28.058335",
     "exception": false,
     "start_time": "2022-11-27T12:51:27.899673",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.to_csv('./df_folds.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c1e881",
   "metadata": {
    "papermill": {
     "duration": 0.006622,
     "end_time": "2022-11-27T12:51:28.072279",
     "exception": false,
     "start_time": "2022-11-27T12:51:28.065657",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b2b1bc9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-27T12:51:28.087336Z",
     "iopub.status.busy": "2022-11-27T12:51:28.086706Z",
     "iopub.status.idle": "2022-11-27T12:51:28.091481Z",
     "shell.execute_reply": "2022-11-27T12:51:28.090593Z"
    },
    "papermill": {
     "duration": 0.014428,
     "end_time": "2022-11-27T12:51:28.093490",
     "exception": false,
     "start_time": "2022-11-27T12:51:28.079062",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "MAX_LENGTH = 512\n",
    "BATCH_SIZE = 4\n",
    "DEBERTA_MODEL = \"../input/debertav3base\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b6f1e3f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-27T12:51:28.121701Z",
     "iopub.status.busy": "2022-11-27T12:51:28.120877Z",
     "iopub.status.idle": "2022-11-27T12:51:29.738448Z",
     "shell.execute_reply": "2022-11-27T12:51:29.737469Z"
    },
    "papermill": {
     "duration": 1.627498,
     "end_time": "2022-11-27T12:51:29.740796",
     "exception": false,
     "start_time": "2022-11-27T12:51:28.113298",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/transformers/convert_slow_tokenizer.py:435: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  \"The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option\"\n"
     ]
    }
   ],
   "source": [
    "tokenizer = transformers.AutoTokenizer.from_pretrained(DEBERTA_MODEL)\n",
    "tokenizer.save_pretrained('./tokenizer/')\n",
    "\n",
    "cfg = transformers.AutoConfig.from_pretrained(DEBERTA_MODEL, output_hidden_states=True)\n",
    "cfg.hidden_dropout_prob = 0\n",
    "cfg.attention_probs_dropout_prob = 0\n",
    "cfg.save_pretrained('./tokenizer/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c563478",
   "metadata": {
    "papermill": {
     "duration": 0.006607,
     "end_time": "2022-11-27T12:51:29.754897",
     "exception": false,
     "start_time": "2022-11-27T12:51:29.748290",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data Process Function\n",
    "\n",
    "To make use of HugggingFace DeBERTa model, we have to tokenize our input texts as the pretrained DeBERTa model requires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6489454",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-27T12:51:29.770117Z",
     "iopub.status.busy": "2022-11-27T12:51:29.769531Z",
     "iopub.status.idle": "2022-11-27T12:51:29.776491Z",
     "shell.execute_reply": "2022-11-27T12:51:29.775631Z"
    },
    "papermill": {
     "duration": 0.016746,
     "end_time": "2022-11-27T12:51:29.778347",
     "exception": false,
     "start_time": "2022-11-27T12:51:29.761601",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def deberta_encode(texts, tokenizer=tokenizer):\n",
    "    input_ids = []\n",
    "    attention_mask = []\n",
    "    \n",
    "    for text in texts.tolist():\n",
    "        token = tokenizer(\n",
    "            text, \n",
    "            add_special_tokens=True, \n",
    "            max_length=MAX_LENGTH, \n",
    "            return_attention_mask=True, \n",
    "            return_tensors=\"np\", \n",
    "            truncation=True, \n",
    "            padding='max_length')\n",
    "        input_ids.append(token['input_ids'][0])\n",
    "        attention_mask.append(token['attention_mask'][0])\n",
    "    \n",
    "    return np.array(input_ids, dtype=\"int32\"), np.array(attention_mask, dtype=\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e942521f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-27T12:51:29.794032Z",
     "iopub.status.busy": "2022-11-27T12:51:29.793220Z",
     "iopub.status.idle": "2022-11-27T12:51:29.798215Z",
     "shell.execute_reply": "2022-11-27T12:51:29.797373Z"
    },
    "papermill": {
     "duration": 0.014922,
     "end_time": "2022-11-27T12:51:29.800304",
     "exception": false,
     "start_time": "2022-11-27T12:51:29.785382",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_dataset(df):\n",
    "    inputs = deberta_encode(df['full_text'])\n",
    "    targets = np.array(df[TARGET_COLS], dtype=\"float32\")\n",
    "    return inputs, targets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98834400",
   "metadata": {
    "papermill": {
     "duration": 0.006561,
     "end_time": "2022-11-27T12:51:29.813864",
     "exception": false,
     "start_time": "2022-11-27T12:51:29.807303",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model\n",
    "\n",
    "### MeanPool\n",
    "\n",
    "Instead of using '[CLS]' token, MeanPool method averaging one layer of hidden states along the sequence axis with masking out padding tokens.\n",
    "\n",
    "### WeightedLayerPool\n",
    "\n",
    "WeightedLayerPool uses a set of trainable weights to average a set of hidden states from transformer backbone. I use a Dense layer with constraint to implement it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "211509ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-27T12:51:29.829584Z",
     "iopub.status.busy": "2022-11-27T12:51:29.828733Z",
     "iopub.status.idle": "2022-11-27T12:51:29.834746Z",
     "shell.execute_reply": "2022-11-27T12:51:29.833896Z"
    },
    "papermill": {
     "duration": 0.016014,
     "end_time": "2022-11-27T12:51:29.836736",
     "exception": false,
     "start_time": "2022-11-27T12:51:29.820722",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MeanPool(tf.keras.layers.Layer):\n",
    "    def call(self, inputs, mask=None):\n",
    "        broadcast_mask = tf.expand_dims(tf.cast(mask, \"float32\"), -1)\n",
    "        embedding_sum = tf.reduce_sum(inputs * broadcast_mask, axis=1)\n",
    "        mask_sum = tf.reduce_sum(broadcast_mask, axis=1)\n",
    "        mask_sum = tf.math.maximum(mask_sum, tf.constant([1e-9]))\n",
    "        return embedding_sum / mask_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c477dba",
   "metadata": {
    "papermill": {
     "duration": 0.008127,
     "end_time": "2022-11-27T12:51:29.851584",
     "exception": false,
     "start_time": "2022-11-27T12:51:29.843457",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "WeightedLayerPool weights constraints: softmax to push sum(w) to be 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f5e7f0b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-27T12:51:29.866727Z",
     "iopub.status.busy": "2022-11-27T12:51:29.865874Z",
     "iopub.status.idle": "2022-11-27T12:51:29.871065Z",
     "shell.execute_reply": "2022-11-27T12:51:29.870058Z"
    },
    "papermill": {
     "duration": 0.014688,
     "end_time": "2022-11-27T12:51:29.873007",
     "exception": false,
     "start_time": "2022-11-27T12:51:29.858319",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class WeightsSumOne(tf.keras.constraints.Constraint):\n",
    "    def __call__(self, w):\n",
    "        return tf.nn.softmax(w, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13c8894",
   "metadata": {
    "papermill": {
     "duration": 0.006535,
     "end_time": "2022-11-27T12:51:29.886179",
     "exception": false,
     "start_time": "2022-11-27T12:51:29.879644",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Model Design Choice\n",
    "\n",
    "To obtain the final representations, we choose to take the last 4 layers hidden states of DeBERTa, take MeanPool of them to gather information along the sequence axis, then take WeightedLayerPool with a set of trainable weights to gather information along the depth axis of the model, then finally a regression head.\n",
    "\n",
    "## Last Layer Reinitialization\n",
    "\n",
    "Reinitialization of the last transformer encoder block: GlorotUniform for Dense kernel, Zeros for Dense bias, Zeros for LayerNorm beta, Ones for LayerNorm gamma.\n",
    "\n",
    "## Layer-wise Learning Rate Decay\n",
    "We use a  MultiOptimizer with initial learning rate $10^{-5}$ for DeBERTa backbone and initial learning rate $10^{-4}$ for the rest of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d892bc3c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-27T12:51:29.903116Z",
     "iopub.status.busy": "2022-11-27T12:51:29.902822Z",
     "iopub.status.idle": "2022-11-27T12:51:29.919420Z",
     "shell.execute_reply": "2022-11-27T12:51:29.918556Z"
    },
    "papermill": {
     "duration": 0.027672,
     "end_time": "2022-11-27T12:51:29.921329",
     "exception": false,
     "start_time": "2022-11-27T12:51:29.893657",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    input_ids = tf.keras.layers.Input(\n",
    "        shape=(MAX_LENGTH,), dtype=tf.int32, name=\"input_ids\"\n",
    "    )\n",
    "    \n",
    "    attention_masks = tf.keras.layers.Input(\n",
    "        shape=(MAX_LENGTH,), dtype=tf.int32, name=\"attention_masks\"\n",
    "    )\n",
    "   \n",
    "    deberta_model = transformers.TFAutoModel.from_pretrained(DEBERTA_MODEL, config=cfg)\n",
    "        \n",
    "    REINIT_LAYERS = 1\n",
    "    normal_initializer = tf.keras.initializers.GlorotUniform()\n",
    "    zeros_initializer = tf.keras.initializers.Zeros()\n",
    "    ones_initializer = tf.keras.initializers.Ones()\n",
    "\n",
    "#     print(f'\\nRe-initializing encoder block:')\n",
    "    for encoder_block in deberta_model.deberta.encoder.layer[-REINIT_LAYERS:]:\n",
    "#         print(f'{encoder_block}')\n",
    "        for layer in encoder_block.submodules:\n",
    "            if isinstance(layer, tf.keras.layers.Dense):\n",
    "                layer.kernel.assign(normal_initializer(shape=layer.kernel.shape, dtype=layer.kernel.dtype))\n",
    "                if layer.bias is not None:\n",
    "                    layer.bias.assign(zeros_initializer(shape=layer.bias.shape, dtype=layer.bias.dtype))\n",
    "\n",
    "            elif isinstance(layer, tf.keras.layers.LayerNormalization):\n",
    "                layer.beta.assign(zeros_initializer(shape=layer.beta.shape, dtype=layer.beta.dtype))\n",
    "                layer.gamma.assign(ones_initializer(shape=layer.gamma.shape, dtype=layer.gamma.dtype))\n",
    "\n",
    "    deberta_output = deberta_model.deberta(\n",
    "        input_ids, attention_mask=attention_masks\n",
    "    )\n",
    "    hidden_states = deberta_output.hidden_states\n",
    "    \n",
    "    #WeightedLayerPool + MeanPool of the last 4 hidden states\n",
    "    stack_meanpool = tf.stack(\n",
    "        [MeanPool()(hidden_s, mask=attention_masks) for hidden_s in hidden_states[-4:]], \n",
    "        axis=2)\n",
    "    \n",
    "    weighted_layer_pool = layers.Dense(1,\n",
    "                                       use_bias=False,\n",
    "                                       kernel_constraint=WeightsSumOne())(stack_meanpool)\n",
    "    \n",
    "    weighted_layer_pool = tf.squeeze(weighted_layer_pool, axis=-1)\n",
    "    #x=layers.Dense(4096,activation='relu')(weighted_layer_pool)\n",
    "    output = layers.Dense(6, activation='linear')(weighted_layer_pool)\n",
    "    \n",
    "   # output = layers.Rescaling(scale=4.0, offset=1.0)(x)\n",
    "    model = tf.keras.Model(inputs=[input_ids, attention_masks], outputs=output)\n",
    "    \n",
    "    #Compile model with Layer-wise Learning Rate Decay\n",
    "    layer_list = [deberta_model.deberta.embeddings] + list(deberta_model.deberta.encoder.layer)\n",
    "    layer_list.reverse()\n",
    "    \n",
    "    INIT_LR = 1e-5\n",
    "    LLRDR = 0.9\n",
    "    LR_SCH_DECAY_STEPS = 1600 # 2 * len(train_df) // BATCH_SIZE\n",
    "    \n",
    "    lr_schedules = [tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "        initial_learning_rate=INIT_LR * LLRDR ** i, \n",
    "        decay_steps=LR_SCH_DECAY_STEPS, \n",
    "        decay_rate=0.3) for i in range(len(layer_list))]\n",
    "    lr_schedule_head = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "        initial_learning_rate=1e-4, \n",
    "        decay_steps=LR_SCH_DECAY_STEPS, \n",
    "        decay_rate=0.3)\n",
    "    \n",
    "    optimizers = [tf.keras.optimizers.Adam(learning_rate=lr_sch) for lr_sch in lr_schedules]\n",
    "    \n",
    "    optimizers_and_layers = [(tf.keras.optimizers.Adam(learning_rate=lr_schedule_head), model.layers[-4:])] +\\\n",
    "        list(zip(optimizers, layer_list))\n",
    "    \n",
    "#     Uncomment next three lines to check optimizers_and_layers\n",
    "#     print('\\nLayer-wise Learning Rate Decay Initial LR:')\n",
    "#     for o,l in optimizers_and_layers:\n",
    "#         print(f'{o._decayed_lr(\"float32\").numpy()} for {l}')\n",
    "        \n",
    "    optimizer = tfa.optimizers.MultiOptimizer(optimizers_and_layers)\n",
    "    \n",
    "    model.compile(optimizer=optimizer,\n",
    "                 loss='mse',\n",
    "                 metrics=[tf.keras.metrics.RootMeanSquaredError()],\n",
    "                 )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "79ced8a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-27T12:51:29.937072Z",
     "iopub.status.busy": "2022-11-27T12:51:29.936212Z",
     "iopub.status.idle": "2022-11-27T12:51:58.770123Z",
     "shell.execute_reply": "2022-11-27T12:51:58.769111Z"
    },
    "papermill": {
     "duration": 28.844477,
     "end_time": "2022-11-27T12:51:58.772916",
     "exception": false,
     "start_time": "2022-11-27T12:51:29.928439",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-27 12:51:31.685843: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-27 12:51:31.686983: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-27 12:51:31.687677: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-27 12:51:31.688521: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-27 12:51:31.688846: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-27 12:51:31.689530: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-27 12:51:31.690221: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-27 12:51:36.459408: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-27 12:51:36.460351: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-27 12:51:36.461043: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-27 12:51:36.461630: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15043 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
      "2022-11-27 12:51:49.098182: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_ids (InputLayer)          [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "attention_masks (InputLayer)    [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "deberta (TFDebertaV2MainLayer)  TFBaseModelOutput(la 183831552   input_ids[0][0]                  \n",
      "                                                                 attention_masks[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "mean_pool (MeanPool)            (None, 768)          0           deberta[0][9]                    \n",
      "                                                                 attention_masks[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "mean_pool_1 (MeanPool)          (None, 768)          0           deberta[0][10]                   \n",
      "                                                                 attention_masks[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "mean_pool_2 (MeanPool)          (None, 768)          0           deberta[0][11]                   \n",
      "                                                                 attention_masks[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "mean_pool_3 (MeanPool)          (None, 768)          0           deberta[0][12]                   \n",
      "                                                                 attention_masks[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf.stack (TFOpLambda)           (None, 768, 4)       0           mean_pool[0][0]                  \n",
      "                                                                 mean_pool_1[0][0]                \n",
      "                                                                 mean_pool_2[0][0]                \n",
      "                                                                 mean_pool_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 768, 1)       4           tf.stack[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.squeeze (TFOpLambd (None, 768)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 6)            4614        tf.compat.v1.squeeze[0][0]       \n",
      "==================================================================================================\n",
      "Total params: 183,836,170\n",
      "Trainable params: 183,836,170\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "model = get_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9caadf1a",
   "metadata": {
    "papermill": {
     "duration": 0.007076,
     "end_time": "2022-11-27T12:51:58.787359",
     "exception": false,
     "start_time": "2022-11-27T12:51:58.780283",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 5 Folds Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e473b253",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-27T12:51:58.802910Z",
     "iopub.status.busy": "2022-11-27T12:51:58.802466Z",
     "iopub.status.idle": "2022-11-27T17:33:13.607209Z",
     "shell.execute_reply": "2022-11-27T17:33:13.605794Z"
    },
    "papermill": {
     "duration": 16874.816632,
     "end_time": "2022-11-27T17:33:13.610870",
     "exception": false,
     "start_time": "2022-11-27T12:51:58.794238",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------FOLD 0 ------------\n",
      "Data prepared.\n",
      "Training data input_ids shape: (3129, 512) dtype: int32\n",
      "Training data attention_mask shape: (3129, 512) dtype: int32\n",
      "Training data targets shape: (3129, 6) dtype: float32\n",
      "Validation data input_ids shape: (782, 512) dtype: int32\n",
      "Validation data attention_mask shape: (782, 512) dtype: int32\n",
      "Validation data targets shape: (782, 6) dtype: float32\n",
      "Model prepared.\n",
      "Start training...\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-27 12:52:16.789491: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "783/783 [==============================] - 416s 477ms/step - loss: 0.3421 - root_mean_squared_error: 0.5849 - val_loss: 0.2118 - val_root_mean_squared_error: 0.4602\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.21179, saving model to best_model_fold0.h5\n",
      "Epoch 2/10\n",
      "783/783 [==============================] - 367s 468ms/step - loss: 0.2093 - root_mean_squared_error: 0.4575 - val_loss: 0.2098 - val_root_mean_squared_error: 0.4580\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.21179 to 0.20977, saving model to best_model_fold0.h5\n",
      "Epoch 3/10\n",
      "783/783 [==============================] - 367s 468ms/step - loss: 0.1920 - root_mean_squared_error: 0.4381 - val_loss: 0.2059 - val_root_mean_squared_error: 0.4538\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.20977 to 0.20590, saving model to best_model_fold0.h5\n",
      "Epoch 4/10\n",
      "783/783 [==============================] - 366s 468ms/step - loss: 0.1829 - root_mean_squared_error: 0.4276 - val_loss: 0.2053 - val_root_mean_squared_error: 0.4530\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.20590 to 0.20525, saving model to best_model_fold0.h5\n",
      "Epoch 5/10\n",
      "783/783 [==============================] - 366s 467ms/step - loss: 0.1772 - root_mean_squared_error: 0.4210 - val_loss: 0.2015 - val_root_mean_squared_error: 0.4488\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.20525 to 0.20145, saving model to best_model_fold0.h5\n",
      "Epoch 6/10\n",
      "783/783 [==============================] - 366s 468ms/step - loss: 0.1735 - root_mean_squared_error: 0.4166 - val_loss: 0.2025 - val_root_mean_squared_error: 0.4500\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.20145\n",
      "Epoch 7/10\n",
      "783/783 [==============================] - 366s 468ms/step - loss: 0.1711 - root_mean_squared_error: 0.4137 - val_loss: 0.2029 - val_root_mean_squared_error: 0.4504\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.20145\n",
      "Epoch 8/10\n",
      "783/783 [==============================] - 367s 469ms/step - loss: 0.1701 - root_mean_squared_error: 0.4124 - val_loss: 0.2025 - val_root_mean_squared_error: 0.4500\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.20145\n",
      "Epoch 00008: early stopping\n",
      "Training finished.\n",
      "\n",
      "-----------FOLD 1 ------------\n",
      "Data prepared.\n",
      "Training data input_ids shape: (3128, 512) dtype: int32\n",
      "Training data attention_mask shape: (3128, 512) dtype: int32\n",
      "Training data targets shape: (3128, 6) dtype: float32\n",
      "Validation data input_ids shape: (783, 512) dtype: int32\n",
      "Validation data attention_mask shape: (783, 512) dtype: int32\n",
      "Validation data targets shape: (783, 6) dtype: float32\n",
      "Model prepared.\n",
      "Start training...\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 384s 446ms/step - loss: 0.4433 - root_mean_squared_error: 0.6658 - val_loss: 0.2377 - val_root_mean_squared_error: 0.4875\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.23767, saving model to best_model_fold1.h5\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 343s 438ms/step - loss: 0.2146 - root_mean_squared_error: 0.4632 - val_loss: 0.2201 - val_root_mean_squared_error: 0.4691\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.23767 to 0.22010, saving model to best_model_fold1.h5\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 343s 438ms/step - loss: 0.2012 - root_mean_squared_error: 0.4486 - val_loss: 0.2155 - val_root_mean_squared_error: 0.4642\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.22010 to 0.21549, saving model to best_model_fold1.h5\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 343s 438ms/step - loss: 0.1907 - root_mean_squared_error: 0.4366 - val_loss: 0.2143 - val_root_mean_squared_error: 0.4629\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.21549 to 0.21431, saving model to best_model_fold1.h5\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 352s 450ms/step - loss: 0.1851 - root_mean_squared_error: 0.4302 - val_loss: 0.2129 - val_root_mean_squared_error: 0.4614\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.21431 to 0.21288, saving model to best_model_fold1.h5\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 342s 438ms/step - loss: 0.1815 - root_mean_squared_error: 0.4260 - val_loss: 0.2130 - val_root_mean_squared_error: 0.4615\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.21288\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 343s 438ms/step - loss: 0.1796 - root_mean_squared_error: 0.4238 - val_loss: 0.2130 - val_root_mean_squared_error: 0.4615\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.21288\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 343s 438ms/step - loss: 0.1786 - root_mean_squared_error: 0.4226 - val_loss: 0.2118 - val_root_mean_squared_error: 0.4602\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.21288 to 0.21178, saving model to best_model_fold1.h5\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 343s 438ms/step - loss: 0.1778 - root_mean_squared_error: 0.4217 - val_loss: 0.2130 - val_root_mean_squared_error: 0.4615\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.21178\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 343s 439ms/step - loss: 0.1776 - root_mean_squared_error: 0.4215 - val_loss: 0.2119 - val_root_mean_squared_error: 0.4603\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.21178\n",
      "Training finished.\n",
      "\n",
      "-----------FOLD 2 ------------\n",
      "Data prepared.\n",
      "Training data input_ids shape: (3129, 512) dtype: int32\n",
      "Training data attention_mask shape: (3129, 512) dtype: int32\n",
      "Training data targets shape: (3129, 6) dtype: float32\n",
      "Validation data input_ids shape: (782, 512) dtype: int32\n",
      "Validation data attention_mask shape: (782, 512) dtype: int32\n",
      "Validation data targets shape: (782, 6) dtype: float32\n",
      "Model prepared.\n",
      "Start training...\n",
      "Epoch 1/10\n",
      "783/783 [==============================] - 421s 478ms/step - loss: 0.3457 - root_mean_squared_error: 0.5880 - val_loss: 0.2419 - val_root_mean_squared_error: 0.4918\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.24189, saving model to best_model_fold2.h5\n",
      "Epoch 2/10\n",
      "783/783 [==============================] - 369s 471ms/step - loss: 0.2041 - root_mean_squared_error: 0.4518 - val_loss: 0.2155 - val_root_mean_squared_error: 0.4642\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.24189 to 0.21553, saving model to best_model_fold2.h5\n",
      "Epoch 3/10\n",
      "783/783 [==============================] - 367s 469ms/step - loss: 0.1865 - root_mean_squared_error: 0.4318 - val_loss: 0.2131 - val_root_mean_squared_error: 0.4617\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.21553 to 0.21312, saving model to best_model_fold2.h5\n",
      "Epoch 4/10\n",
      "783/783 [==============================] - 368s 469ms/step - loss: 0.1779 - root_mean_squared_error: 0.4218 - val_loss: 0.2139 - val_root_mean_squared_error: 0.4625\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.21312\n",
      "Epoch 5/10\n",
      "783/783 [==============================] - 368s 470ms/step - loss: 0.1718 - root_mean_squared_error: 0.4145 - val_loss: 0.2112 - val_root_mean_squared_error: 0.4596\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.21312 to 0.21121, saving model to best_model_fold2.h5\n",
      "Epoch 6/10\n",
      "783/783 [==============================] - 368s 470ms/step - loss: 0.1680 - root_mean_squared_error: 0.4099 - val_loss: 0.2128 - val_root_mean_squared_error: 0.4613\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.21121\n",
      "Epoch 7/10\n",
      "783/783 [==============================] - 368s 470ms/step - loss: 0.1661 - root_mean_squared_error: 0.4075 - val_loss: 0.2121 - val_root_mean_squared_error: 0.4605\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.21121\n",
      "Epoch 8/10\n",
      "783/783 [==============================] - 368s 470ms/step - loss: 0.1649 - root_mean_squared_error: 0.4061 - val_loss: 0.2119 - val_root_mean_squared_error: 0.4603\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.21121\n",
      "Epoch 00008: early stopping\n",
      "Training finished.\n",
      "\n",
      "-----------FOLD 3 ------------\n",
      "Data prepared.\n",
      "Training data input_ids shape: (3129, 512) dtype: int32\n",
      "Training data attention_mask shape: (3129, 512) dtype: int32\n",
      "Training data targets shape: (3129, 6) dtype: float32\n",
      "Validation data input_ids shape: (782, 512) dtype: int32\n",
      "Validation data attention_mask shape: (782, 512) dtype: int32\n",
      "Validation data targets shape: (782, 6) dtype: float32\n",
      "Model prepared.\n",
      "Start training...\n",
      "Epoch 1/10\n",
      "783/783 [==============================] - 418s 479ms/step - loss: 0.3883 - root_mean_squared_error: 0.6231 - val_loss: 0.2314 - val_root_mean_squared_error: 0.4810\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.23139, saving model to best_model_fold3.h5\n",
      "Epoch 2/10\n",
      "783/783 [==============================] - 369s 471ms/step - loss: 0.2077 - root_mean_squared_error: 0.4557 - val_loss: 0.2085 - val_root_mean_squared_error: 0.4566\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.23139 to 0.20851, saving model to best_model_fold3.h5\n",
      "Epoch 3/10\n",
      "783/783 [==============================] - 369s 471ms/step - loss: 0.1909 - root_mean_squared_error: 0.4370 - val_loss: 0.2190 - val_root_mean_squared_error: 0.4679\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.20851\n",
      "Epoch 4/10\n",
      "783/783 [==============================] - 369s 471ms/step - loss: 0.1821 - root_mean_squared_error: 0.4268 - val_loss: 0.2111 - val_root_mean_squared_error: 0.4594\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.20851\n",
      "Epoch 5/10\n",
      "783/783 [==============================] - 369s 471ms/step - loss: 0.1762 - root_mean_squared_error: 0.4198 - val_loss: 0.2079 - val_root_mean_squared_error: 0.4560\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.20851 to 0.20792, saving model to best_model_fold3.h5\n",
      "Epoch 6/10\n",
      "783/783 [==============================] - 369s 471ms/step - loss: 0.1722 - root_mean_squared_error: 0.4149 - val_loss: 0.2067 - val_root_mean_squared_error: 0.4547\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.20792 to 0.20675, saving model to best_model_fold3.h5\n",
      "Epoch 7/10\n",
      "783/783 [==============================] - 369s 472ms/step - loss: 0.1705 - root_mean_squared_error: 0.4130 - val_loss: 0.2081 - val_root_mean_squared_error: 0.4561\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.20675\n",
      "Epoch 8/10\n",
      "783/783 [==============================] - 369s 471ms/step - loss: 0.1693 - root_mean_squared_error: 0.4115 - val_loss: 0.2064 - val_root_mean_squared_error: 0.4543\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.20675 to 0.20643, saving model to best_model_fold3.h5\n",
      "Epoch 9/10\n",
      "783/783 [==============================] - 369s 471ms/step - loss: 0.1685 - root_mean_squared_error: 0.4104 - val_loss: 0.2068 - val_root_mean_squared_error: 0.4548\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.20643\n",
      "Epoch 10/10\n",
      "783/783 [==============================] - 369s 472ms/step - loss: 0.1681 - root_mean_squared_error: 0.4100 - val_loss: 0.2065 - val_root_mean_squared_error: 0.4544\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.20643\n",
      "Training finished.\n",
      "\n",
      "-----------FOLD 4 ------------\n",
      "Data prepared.\n",
      "Training data input_ids shape: (3129, 512) dtype: int32\n",
      "Training data attention_mask shape: (3129, 512) dtype: int32\n",
      "Training data targets shape: (3129, 6) dtype: float32\n",
      "Validation data input_ids shape: (782, 512) dtype: int32\n",
      "Validation data attention_mask shape: (782, 512) dtype: int32\n",
      "Validation data targets shape: (782, 6) dtype: float32\n",
      "Model prepared.\n",
      "Start training...\n",
      "Epoch 1/10\n",
      "783/783 [==============================] - 418s 480ms/step - loss: 0.3817 - root_mean_squared_error: 0.6178 - val_loss: 0.2253 - val_root_mean_squared_error: 0.4747\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.22531, saving model to best_model_fold4.h5\n",
      "Epoch 2/10\n",
      "783/783 [==============================] - 369s 472ms/step - loss: 0.2120 - root_mean_squared_error: 0.4604 - val_loss: 0.2153 - val_root_mean_squared_error: 0.4640\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.22531 to 0.21528, saving model to best_model_fold4.h5\n",
      "Epoch 3/10\n",
      "783/783 [==============================] - 370s 473ms/step - loss: 0.1965 - root_mean_squared_error: 0.4432 - val_loss: 0.2081 - val_root_mean_squared_error: 0.4562\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.21528 to 0.20810, saving model to best_model_fold4.h5\n",
      "Epoch 4/10\n",
      "783/783 [==============================] - 370s 472ms/step - loss: 0.1863 - root_mean_squared_error: 0.4316 - val_loss: 0.2053 - val_root_mean_squared_error: 0.4531\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.20810 to 0.20526, saving model to best_model_fold4.h5\n",
      "Epoch 5/10\n",
      "783/783 [==============================] - 369s 471ms/step - loss: 0.1805 - root_mean_squared_error: 0.4249 - val_loss: 0.2049 - val_root_mean_squared_error: 0.4527\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.20526 to 0.20493, saving model to best_model_fold4.h5\n",
      "Epoch 6/10\n",
      "783/783 [==============================] - 369s 471ms/step - loss: 0.1777 - root_mean_squared_error: 0.4215 - val_loss: 0.2036 - val_root_mean_squared_error: 0.4513\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.20493 to 0.20363, saving model to best_model_fold4.h5\n",
      "Epoch 7/10\n",
      "783/783 [==============================] - 369s 472ms/step - loss: 0.1759 - root_mean_squared_error: 0.4193 - val_loss: 0.2041 - val_root_mean_squared_error: 0.4518\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.20363\n",
      "Epoch 8/10\n",
      "783/783 [==============================] - 370s 472ms/step - loss: 0.1745 - root_mean_squared_error: 0.4177 - val_loss: 0.2057 - val_root_mean_squared_error: 0.4536\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.20363\n",
      "Epoch 9/10\n",
      "783/783 [==============================] - 370s 472ms/step - loss: 0.1740 - root_mean_squared_error: 0.4172 - val_loss: 0.2041 - val_root_mean_squared_error: 0.4518\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.20363\n",
      "Epoch 00009: early stopping\n",
      "Training finished.\n"
     ]
    }
   ],
   "source": [
    "valid_rmses = []\n",
    "for fold in range(N_FOLD):\n",
    "    print(f'\\n-----------FOLD {fold} ------------')\n",
    "    \n",
    "    #Create dataset\n",
    "    train_df = df[df['fold'] != fold].reset_index(drop=True)\n",
    "    valid_df = df[df['fold'] == fold].reset_index(drop=True)\n",
    "    train_dataset = get_dataset(train_df)\n",
    "    valid_dataset = get_dataset(valid_df)\n",
    "    \n",
    "    print('Data prepared.')\n",
    "    print(f'Training data input_ids shape: {train_dataset[0][0].shape} dtype: {train_dataset[0][0].dtype}') \n",
    "    print(f'Training data attention_mask shape: {train_dataset[0][1].shape} dtype: {train_dataset[0][1].dtype}')\n",
    "    print(f'Training data targets shape: {train_dataset[1].shape} dtype: {train_dataset[1].dtype}')\n",
    "    print(f'Validation data input_ids shape: {valid_dataset[0][0].shape} dtype: {valid_dataset[0][0].dtype}')\n",
    "    print(f'Validation data attention_mask shape: {valid_dataset[0][1].shape} dtype: {valid_dataset[0][1].dtype}')\n",
    "    print(f'Validation data targets shape: {valid_dataset[1].shape} dtype: {valid_dataset[1].dtype}')\n",
    "    \n",
    "    #Create model\n",
    "    tf.keras.backend.clear_session()\n",
    "    model = get_model()\n",
    "    print('Model prepared.')\n",
    "    \n",
    "    #Training model\n",
    "    print('Start training...')\n",
    "    callbacks = [\n",
    "        tf.keras.callbacks.ModelCheckpoint(\n",
    "            f\"best_model_fold{fold}.h5\",\n",
    "            monitor=\"val_loss\",\n",
    "            mode=\"min\",\n",
    "            save_best_only=True,\n",
    "            verbose=1,\n",
    "            save_weights_only=True,),\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss', \n",
    "            min_delta=1e-5, \n",
    "            patience=3, \n",
    "            verbose=1,\n",
    "            mode='min',)\n",
    "        ]\n",
    "    history = model.fit(\n",
    "        x=train_dataset[0],\n",
    "        y=train_dataset[1],\n",
    "        validation_data=valid_dataset, \n",
    "        epochs=10,\n",
    "        shuffle=True,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        callbacks=callbacks)\n",
    "    \n",
    "    valid_rmses.append(np.min(history.history['val_root_mean_squared_error']))\n",
    "    print('Training finished.')\n",
    "    del train_dataset, valid_dataset, train_df, valid_df\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e85e5a21",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-27T17:33:21.511619Z",
     "iopub.status.busy": "2022-11-27T17:33:21.510932Z",
     "iopub.status.idle": "2022-11-27T17:33:21.567006Z",
     "shell.execute_reply": "2022-11-27T17:33:21.565579Z"
    },
    "papermill": {
     "duration": 2.027527,
     "end_time": "2022-11-27T17:33:21.569555",
     "exception": false,
     "start_time": "2022-11-27T17:33:19.542028",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 Folds validation RMSE:\n",
      "[0.448834091424942, 0.4601999521255493, 0.4595765173435211, 0.4543420970439911, 0.4512515664100647]\n",
      "Local CV Average score: 0.4548408448696136\n"
     ]
    }
   ],
   "source": [
    "print(f'{len(valid_rmses)} Folds validation RMSE:\\n{valid_rmses}')\n",
    "print(f'Local CV Average score: {np.mean(valid_rmses)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3f1a88",
   "metadata": {
    "papermill": {
     "duration": 2.10276,
     "end_time": "2022-11-27T17:33:25.650131",
     "exception": false,
     "start_time": "2022-11-27T17:33:23.547371",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "80750ab8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-27T17:33:29.574711Z",
     "iopub.status.busy": "2022-11-27T17:33:29.574003Z",
     "iopub.status.idle": "2022-11-27T17:33:29.603234Z",
     "shell.execute_reply": "2022-11-27T17:33:29.602261Z"
    },
    "papermill": {
     "duration": 1.989287,
     "end_time": "2022-11-27T17:33:29.605301",
     "exception": false,
     "start_time": "2022-11-27T17:33:27.616014",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>full_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000C359D63E</td>\n",
       "      <td>when a person has no experience on a job their...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000BAD50D026</td>\n",
       "      <td>Do you think students would benefit from being...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00367BB2546B</td>\n",
       "      <td>Thomas Jefferson once states that \"it is wonde...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        text_id                                          full_text\n",
       "0  0000C359D63E  when a person has no experience on a job their...\n",
       "1  000BAD50D026  Do you think students would benefit from being...\n",
       "2  00367BB2546B  Thomas Jefferson once states that \"it is wonde..."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv('../input/feedback-prize-english-language-learning/test.csv')\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fb53eb16",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-27T17:33:34.072443Z",
     "iopub.status.busy": "2022-11-27T17:33:34.072088Z",
     "iopub.status.idle": "2022-11-27T17:33:34.092311Z",
     "shell.execute_reply": "2022-11-27T17:33:34.091168Z"
    },
    "papermill": {
     "duration": 2.342839,
     "end_time": "2022-11-27T17:33:34.094510",
     "exception": false,
     "start_time": "2022-11-27T17:33:31.751671",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_dataset = deberta_encode(test_df['full_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "048ae5ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-27T17:33:42.168034Z",
     "iopub.status.busy": "2022-11-27T17:33:42.167650Z",
     "iopub.status.idle": "2022-11-27T17:36:00.161345Z",
     "shell.execute_reply": "2022-11-27T17:36:00.160338Z"
    },
    "papermill": {
     "duration": 139.944779,
     "end_time": "2022-11-27T17:36:00.164084",
     "exception": false,
     "start_time": "2022-11-27T17:33:40.219305",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 0 inference...\n",
      "\n",
      "Fold 1 inference...\n",
      "\n",
      "Fold 2 inference...\n",
      "\n",
      "Fold 3 inference...\n",
      "\n",
      "Fold 4 inference...\n"
     ]
    }
   ],
   "source": [
    "fold_preds = []\n",
    "for fold in range(N_FOLD):\n",
    "    tf.keras.backend.clear_session()\n",
    "    model = get_model()\n",
    "    model.load_weights(f'best_model_fold{fold}.h5')\n",
    "    print(f'\\nFold {fold} inference...')\n",
    "    pred = model.predict(test_dataset, batch_size=BATCH_SIZE)\n",
    "    fold_preds.append(pred)\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6300aea8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-27T17:36:04.169458Z",
     "iopub.status.busy": "2022-11-27T17:36:04.169091Z",
     "iopub.status.idle": "2022-11-27T17:36:04.205474Z",
     "shell.execute_reply": "2022-11-27T17:36:04.204443Z"
    },
    "papermill": {
     "duration": 2.074781,
     "end_time": "2022-11-27T17:36:04.208305",
     "exception": false,
     "start_time": "2022-11-27T17:36:02.133524",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "preds = np.mean(fold_preds, axis=0)\n",
    "preds = np.clip(preds, 1, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "049fb3f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-27T17:36:08.611075Z",
     "iopub.status.busy": "2022-11-27T17:36:08.610696Z",
     "iopub.status.idle": "2022-11-27T17:36:08.619314Z",
     "shell.execute_reply": "2022-11-27T17:36:08.618438Z"
    },
    "papermill": {
     "duration": 2.419768,
     "end_time": "2022-11-27T17:36:08.621302",
     "exception": false,
     "start_time": "2022-11-27T17:36:06.201534",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub_df = pd.concat([test_df[['text_id']], pd.DataFrame(preds, columns=TARGET_COLS)], axis=1)\n",
    "sub_df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a330eb59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-27T17:36:12.673375Z",
     "iopub.status.busy": "2022-11-27T17:36:12.673001Z",
     "iopub.status.idle": "2022-11-27T17:36:12.685959Z",
     "shell.execute_reply": "2022-11-27T17:36:12.684949Z"
    },
    "papermill": {
     "duration": 1.97707,
     "end_time": "2022-11-27T17:36:12.687869",
     "exception": false,
     "start_time": "2022-11-27T17:36:10.710799",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>cohesion</th>\n",
       "      <th>syntax</th>\n",
       "      <th>vocabulary</th>\n",
       "      <th>phraseology</th>\n",
       "      <th>grammar</th>\n",
       "      <th>conventions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000C359D63E</td>\n",
       "      <td>2.873056</td>\n",
       "      <td>2.733107</td>\n",
       "      <td>3.055208</td>\n",
       "      <td>2.928910</td>\n",
       "      <td>2.671607</td>\n",
       "      <td>2.669564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000BAD50D026</td>\n",
       "      <td>2.696459</td>\n",
       "      <td>2.468592</td>\n",
       "      <td>2.729108</td>\n",
       "      <td>2.404995</td>\n",
       "      <td>2.142427</td>\n",
       "      <td>2.579038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00367BB2546B</td>\n",
       "      <td>3.652248</td>\n",
       "      <td>3.403617</td>\n",
       "      <td>3.597492</td>\n",
       "      <td>3.539529</td>\n",
       "      <td>3.376834</td>\n",
       "      <td>3.321722</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        text_id  cohesion    syntax  vocabulary  phraseology   grammar  \\\n",
       "0  0000C359D63E  2.873056  2.733107    3.055208     2.928910  2.671607   \n",
       "1  000BAD50D026  2.696459  2.468592    2.729108     2.404995  2.142427   \n",
       "2  00367BB2546B  3.652248  3.403617    3.597492     3.539529  3.376834   \n",
       "\n",
       "   conventions  \n",
       "0     2.669564  \n",
       "1     2.579038  \n",
       "2     3.321722  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 17105.2252,
   "end_time": "2022-11-27T17:36:17.908543",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-11-27T12:51:12.683343",
   "version": "2.3.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "c710fb56eb8a424639b774445b68a089fceea3db132060601e1ae5682d789ba1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
